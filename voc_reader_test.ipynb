{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenfeng/anaconda3/envs/AlphaGo/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import inputs.voc2012 as voc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx2names(idxs):\n",
    "    return [voc.all_classes[i] for i in range(len(idxs)) if idxs[i] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-20 17:37:21,623 root INFO Reading list file for images...\n",
      "2017-12-20 17:37:21,762 root INFO Done list reading(train), 5717 images in total!\n",
      "(500, 333, 3) (20,)\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    data = voc.ImageReader('./data/voc/JPEGImages/', './data/voc/ImageSets/Main/', 'train')\n",
    "    with tf.train.MonitoredSession() as sess:\n",
    "        image, label = sess.run([data.image, data.label])\n",
    "        image, label = sess.run([data.image, data.label])\n",
    "        print(image.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-20 17:37:24,880 root INFO Reading list file for images...\n",
      "2017-12-20 17:37:25,023 root INFO Done list reading(train), 5717 images in total!\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    data = voc.ImageReader('./data/voc/JPEGImages/', './data/voc/ImageSets/Main/', 'train')\n",
    "    sess = tf.train.MonitoredSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 500, 3)\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "image, label = sess.run([data.image, data.label])\n",
    "plt.imshow(image)\n",
    "plt.title(' '.join(idx2names(label)))\n",
    "plt.show()\n",
    "print(image.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_prep(img, shp=(224, 224)):\n",
    "    img = tf.image.resize_images(img, shp)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-20 17:45:01,451 root INFO Reading list file for images...\n",
      "2017-12-20 17:45:01,596 root INFO Done list reading(train), 5717 images in total!\n",
      "0 (32, 224, 224, 3) (32, 20)\n",
      "50 (32, 224, 224, 3) (32, 20)\n",
      "100 (32, 224, 224, 3) (32, 20)\n",
      "150 (32, 224, 224, 3) (32, 20)\n",
      "200 (32, 224, 224, 3) (32, 20)\n",
      "250 (32, 224, 224, 3) (32, 20)\n",
      "300 (32, 224, 224, 3) (32, 20)\n",
      "350 (32, 224, 224, 3) (32, 20)\n",
      "400 (32, 224, 224, 3) (32, 20)\n",
      "450 (32, 224, 224, 3) (32, 20)\n",
      "500 (32, 224, 224, 3) (32, 20)\n",
      "550 (32, 224, 224, 3) (32, 20)\n",
      "600 (32, 224, 224, 3) (32, 20)\n",
      "650 (32, 224, 224, 3) (32, 20)\n",
      "700 (32, 224, 224, 3) (32, 20)\n",
      "750 (32, 224, 224, 3) (32, 20)\n",
      "800 (32, 224, 224, 3) (32, 20)\n",
      "850 (32, 224, 224, 3) (32, 20)\n",
      "900 (32, 224, 224, 3) (32, 20)\n",
      "950 (32, 224, 224, 3) (32, 20)\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    data = voc.ImageReader('./data/voc/JPEGImages/', './data/voc/ImageSets/Main/', 'train', prep_func=my_prep)\n",
    "    batch_images, batch_labels = data.data_batch(32)\n",
    "    with tf.train.MonitoredSession() as sess:\n",
    "        for i in range(1000):\n",
    "            images, labels = sess.run([batch_images, batch_labels])\n",
    "            if i % 50 == 0:\n",
    "                print(i, images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
